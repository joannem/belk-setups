input {
    kafka {
        bootstrap_servers => "broker:29092"
        topics_pattern => "test_[\-_a-z]*_pf3_hit_stats"
        metadata_max_age_ms => 60000
        group_id => "logstash"
        client_id => "logstash-1"
    }
}

filter {
    csv {
        columns => [
           "msg_timestamp", "schema_id", "hit_timestamp", "flow_id", "link_ref",
           "mission", "rule_name", "src_ip", "dst_ip", "src_port", "dst_port", "fwd_by",
           "mod8_hash", "mod16_hash"
        ]
        convert => {
            "msg_timestamp" => date_time
            "src_port" => integer
            "dst_port" => integer
            "mod8_hash" => integer
            "mod16_hash" => integer
        }
    }
}

output {
    elasticsearch {
        hosts => [ "https://es01:9200" ]
        data_stream => true
        ssl => true
        cacert => "/usr/share/logstash/elasticsearch-certs/ca/ca.crt"
        api_key => "boUXzYQBQ7hVylT0_zUv:VmgzGtTcSa29zNbn85iP3w"
    }
    stdout {
        codec => rubydebug
    }
}
